---
title: "EDA"
author: "Sehyun Oh"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
suppressPackageStartupMessages({
  library(curatedMetagenomicData)
  library(PCAGenomicSignatures)
})

```

```{r}
cMD_all <- curatedMetagenomicData("*")
study <- sapply(cMD_all, function(x) {stringr::str_split(x, "\\.") %>% unlist %>% .[1]})
type <- sapply(cMD_all, function(x) {stringr::str_split(x, "\\.") %>% unlist %>% .[2]})
site <- sapply(cMD_all, function(x) {stringr::str_split(x, "\\.") %>% unlist %>% .[3]})
```

```{r}
length(unique(study))
length(unique(type))
length(unique(site))
```

```{r}
unique(type)
unique(site)
```

## `marker_abundance.stool` datasets
```{r}
x <- grep("marker_abundance.stool", cMD_all)
dataset_list <- cMD_all[x]
```

```{r message=FALSE, warning=FALSE, eval=FALSE}
data <- curatedMetagenomicData(dataset_list, dryrun = FALSE)
```


## Subset to common features
```{r eval=FALSE}
allFeatures <- lapply(data, rownames)
commonFeatures <- Reduce(intersect, allFeatures) 
```

```{r eval=FALSE}
# data subset to common features
data_cf <- lapply(data, function(x) x[commonFeatures,])
```

```{r fig.width=4, fig.height=3, eval=FALSE}
numOfSamples <- sapply(seq_along(data_cf), function(x) ncol(data_cf[[x]]))
summary(numOfSamples)

hist(numOfSamples, breaks = seq(0, 1000, 5), xlim = c(0, 100))
```

Remove 1 dataset with <20 samples.
```{r, eval=FALSE}
ind <- which(numOfSamples < 20)
data_forPCA <- data_cf[-1]
```

```{r echo=FALSE, eval=FALSE}
save(data_forPCA, file = "~/data/MicrobiomeWorkshop/inst/extdata/data_forPCA.rds")
rm(data, data_cf)
```

```{r echo=FALSE}
load("~/data/MicrobiomeWorkshop/inst/extdata/data_forPCA.rds")
```



## PCA
```{r}
## An empty list for PCA results (rotation and variance)
trainingData_PCA <- vector("list", length(data_forPCA))
names(trainingData_PCA) <- names(data_forPCA)
```

```{r}
n <- 20
for (i in seq_along(data_forPCA)) {
  x <- exprs(data_forPCA[[i]])
  study <- names(data_forPCA)[i]
  
  pca_res <- prcomp(t(x))
  trainingData_PCA[[study]]$rotation <- pca_res$rotation[,1:n]
  colnames(trainingData_PCA[[study]]$rotation) <- paste0(study, ".PC", c(1:n))
  eigs <- pca_res$sdev^2
  pca_summary <- rbind(SD = sqrt(eigs),
                       Variance = eigs/sum(eigs),
                       Cumulative = cumsum(eigs)/sum(eigs))
  trainingData_PCA[[study]]$variance <- pca_summary[,1:n]
  colnames(trainingData_PCA[[study]]$variance) <- paste0(study, ".PC", c(1:n))
}
```

### Variance Explained
It seems like that almost 95% of variance is explained within PC7-8. 
```{r fig.width=5, fig.height=4}
x <- trainingData_PCA

plot(x[[1]]$variance[2,], type = "l", xlab = "PCs", ylab = "Variance Explained")
for (i in 2:length(x)) {
  lines(x[[i]]$variance[2,])
}
abline(h = 0.05, col = "red")
```

## Combine all PCs
```{r}
## Combine all PCs
allZ_list <- lapply(trainingData_PCA, function(x) x$rotation)
allZ <- Reduce(cbind, allZ_list)
all <- t(allZ)   # a matrix of PCs (row) x genes (column)
```

### Subset PCss
For now, I'm using top 10 PCs based on variance explained.
```{r}
ind <- c()
numOfDataset <- length(trainingData_PCA)
numOfTopPCs <- 20
for (i in 1:numOfDataset) {new_ind = c(1:10) + numOfTopPCs*(i-1); ind = c(ind, new_ind)}

all <- t(allZ)[ind,]
```


### Dendrogram
Here I'm testing the ideal number of clusters.

```{r distinct_colors, echo=FALSE}
library(RColorBrewer)
n <- 60
qual_col_pals = brewer.pal.info[brewer.pal.info$category == 'qual',]
col_vector = unlist(mapply(brewer.pal, qual_col_pals$maxcolors, rownames(qual_col_pals)))
```

```{r}
m <- "spearman"
ag <- "ward.D"
k <- 50
res.dist.dend <- factoextra::get_dist(all, method = m)
res.hcut.dend <- factoextra::hcut(res.dist, k = k, hc_funct = "hclust", 
                                  hc_method = ag, hc_metric = m)
col <- col_vector[1:res.hcut.dend$nbclust]
factoextra::fviz_dend(res.hcut.dend, k = k, cex = 0.5, 
                      rect = TRUE, palette = col,
                      rect_fill = TRUE, rect_border = col,
                      main = paste(m, ag, "with k =", k))
```

### Hierarchical Clustering
```{r}
## Calculate distance
res.dist <- factoextra::get_dist(all, method = "spearman")

## Cut the tree
# k <- round(nrow(all)/4,0)
k <- 50
res.hcut <- factoextra::hcut(res.dist, k = k, hc_func = "hclust", 
                             hc_method = "ward.D", hc_metric = "spearman")
```

```{r}
trainingData_PCclusters <- buildAvgLoading(t(all), clustering = FALSE, 
                                           cluster = res.hcut$cluster, iter.max = 100)
```      

Size of each clusters
```{r fig.width=5, fig.height=4}
hist(trainingData_PCclusters$size, breaks = seq(0, 100, 5),
     main = "Distribution of Cluster Sizes",
     xlab = "Cluster Size", ylab = "Frequency")
```

```{r}
## Silhouette Width
cl <- trainingData_PCclusters$cluster
silh_res <- cluster::silhouette(cl, res.dist)
cl_silh_width <- summary(silh_res)$clus.avg.widths
trainingData_PCclusters$sw <- cl_silh_width  # add silhouette width to the result
```

```{r}
## Variance Explained from PCA result
pca_summary <- list()
for (i in seq_along(trainingData_PCA)) {
    pca_summary[[i]] <- trainingData_PCA[[i]]$variance
    names(pca_summary)[i] <- names(trainingData_PCA)[i]
}
```

```{r}
trainingDatasets <- "cMD"
note <- "marker_abundance.stool/ dataset with >20 samples"
```

```{r}
PCAmodel <- PCAGenomicSignatures(assays = list(model = as.matrix(trainingData_PCclusters$avgLoading)))
metadata(PCAmodel) <- trainingData_PCclusters[c("cluster", "size", "k", "n")]
studies(PCAmodel) <- trainingData_PCclusters$studies
silhouetteWidth(PCAmodel) <- trainingData_PCclusters$sw
# metadata(PCAmodel)$MeSH_freq <- MeSH_freq
trainingData(PCAmodel)$PCAsummary <- pca_summary
# mesh(PCAmodel) <- trainingData_MeSH
updateNote(PCAmodel) <- note
```

Resulting model is versoned for different building details. Check the README.md.
```{r eval=FALSE}
save(PCAmodel, file = "~/data/MicrobiomeWorkshop/inst/extdata/PCAmodel_marker_abundance.stool.rds")
```

```{r}
load("~/data/MicrobiomeWorkshop/inst/extdata/PCAmodel_marker_abundance.stool.rds")
```

```{r}
unique_studies <- sapply(colData(PCAmodel)$studies, length)
all_studies <- metadata(PCAmodel)$size
df <- data.frame(unique = unique_studies, all = all_studies)
df$redundant <- df$all - df$unique

t(df)
```
